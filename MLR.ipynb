{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "C2uEt6ECeG3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__)\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy.lib.function_base import vectorize\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from numpy.core.fromnumeric import size\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2iu9jfOyXCG",
        "outputId": "a1cc1a2b-d47e-4f25-e948-72a52131239b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data-Set"
      ],
      "metadata": {
        "id": "wxFMiYVheYRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データの読み込み\n",
        "df_2007 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/test/data_set_2007.csv\", header=0)\n",
        "df_2008 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/test/data_set_2008.csv\", header=0)\n",
        "df_2009 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/test/data_set_2009.csv\", header=0)\n",
        "df_2010 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/test/data_set_2010.csv\", header=0)\n",
        "df_2011 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/test/data_set_2011.csv\", header=0)\n",
        "df_2012 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/test/data_set_2012.csv\", header=0)\n",
        "df_2013 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/test/data_set_2013.csv\", header=0)\n",
        "df_2014 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/test/data_set_2014.csv\", header=0)\n",
        "df_2015 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/test/data_set_2015.csv\", header=0)\n",
        "df_2016 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/test/data_set_2016.csv\", header=0)\n",
        "df_2017 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/test/data_set_2017.csv\", header=0)\n",
        "df_2018 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/test/data_set_2018.csv\", header=0)\n",
        "df_2019 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/test/data_set_2019.csv\", header=0)\n",
        "\n",
        "# df_0000 storage list\n",
        "list_df = [df_2007, df_2008, df_2009, df_2010, df_2011, df_2012, df_2013, df_2014, df_2015, df_2016, df_2017, df_2018, df_2019]"
      ],
      "metadata": {
        "id": "mi3BWBebeRLv"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading and data splitting"
      ],
      "metadata": {
        "id": "3rmQiwieyvmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def DataMake(split, metric, list_df):\n",
        "  # variable\n",
        "  label_train = []\n",
        "  label_test = []\n",
        "  sentences_train = []\n",
        "  sentences_test = []\n",
        "\n",
        "  # Split the correct answer labels and target sentences into study and test.\n",
        "  list_train = list_df[:split]\n",
        "  list_test = list_df[split:]\n",
        "  print('metric:', metric)\n",
        "  print('train:', len(list_train), 'test:', len(list_test))\n",
        "\n",
        "  # Store data frames for testing in df_test.\n",
        "  df_test = pd.concat(list_test)\n",
        "\n",
        "  # Extract and list metric value in a list.\n",
        "  for i in list_train:\n",
        "    label_train.append(i[metric].values)\n",
        "    sentences_train.append(i['Description'].values)\n",
        "  for i in list_test:\n",
        "    label_test.append(i[metric].values)\n",
        "    sentences_test.append(i['Description'].values)\n",
        "\n",
        "  # data for input\n",
        "  # metric value\n",
        "  y_train = np.concatenate(label_train, 0)\n",
        "  y_test = np.concatenate(label_test, 0)\n",
        "  # description\n",
        "  train_sentence = np.concatenate(sentences_train, 0)\n",
        "  test_sentence = np.concatenate(sentences_test, 0)\n",
        "\n",
        "  return y_train, y_test, train_sentence, test_sentence, df_test"
      ],
      "metadata": {
        "id": "7EFClJiGyi7y"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Natural Language Processing (train)"
      ],
      "metadata": {
        "id": "YfYxevRwfneG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def NLP_train(train_sentence):\n",
        "  # Natural Language Processing\n",
        "  # Creating BoW features with sklearn's CountVectorizer\n",
        "  vectorizer = CountVectorizer(stop_words=\"english\")\n",
        "  X_train = vectorizer.fit_transform(train_sentence)\n",
        "  \n",
        "  return X_train, vectorizer"
      ],
      "metadata": {
        "id": "UFh_yTKG_L3d"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multinomial Logistic Regression (train)"
      ],
      "metadata": {
        "id": "OhGKDuML0g93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MLR_train(X_train, y_train):\n",
        "  # Create a classification model for MLR using vectorized features\n",
        "  lr = LogisticRegression(C=0.3, random_state=0, n_jobs=-1)\n",
        "  lr.fit(X_train, y_train)\n",
        "\n",
        "  return lr\n",
        "\n"
      ],
      "metadata": {
        "id": "A-Y15tpr_9jv"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Natural Language Processing (test)"
      ],
      "metadata": {
        "id": "A1MAf62J0tPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def NLP_test(test_sentence, vectorizer):\n",
        "  # Natural Language Processing\n",
        "  # Creating BoW features with sklearn's CountVectorizer.\n",
        "  X_test = vectorizer.transform(test_sentence)\n",
        "  \n",
        "  return X_test"
      ],
      "metadata": {
        "id": "JVv9EtnWlZrm"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multinomial Logistic Regression (test)"
      ],
      "metadata": {
        "id": "2rxS6KVU0vh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MLR_test(metric, X_test, y_test, lr):\n",
        "  # Test data to confirm accuracy.\n",
        "  y_pred = lr.predict(X_test)\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "  # Branching when creating a table.\n",
        "  if metric == 'AV':\n",
        "    table = pd.DataFrame(cm, columns=['Predicted P', 'Predicted L', 'Predicted A', 'Predicted N'], index=['Actual P', 'Actual L', 'Actual A', 'Actual N'])\n",
        "  elif metric == 'AC':\n",
        "    table = pd.DataFrame(cm, columns=['Predicted L', 'Predicted H'], index=['Actual L', 'Actual H'])\n",
        "  elif metric == 'PR':\n",
        "    table = pd.DataFrame(cm, columns=['Predicted N', 'Predicted L', 'Predicted H'], index=['Actual N', 'Actual L', 'Actual H'])\n",
        "  elif metric == 'UI':\n",
        "    table = pd.DataFrame(cm, columns=['Predicted N', 'Predicted R'], index=['Actual N', 'Actual R'])\n",
        "  elif metric == 'S':\n",
        "    table = pd.DataFrame(cm, columns=['Predicted U', 'Predicted C'], index=['Actual U', 'Actual C'])\n",
        "  else:\n",
        "    table = pd.DataFrame(cm, columns=['Predicted N', 'Predicted L', 'Predicted H'], index=['Actual N', 'Actual L', 'Actual H'])\n",
        "\n",
        "  # Accuracy\n",
        "  print(\"accuracy:\", accuracy_score(y_test, y_pred))\n",
        "  print(table)\n",
        "  print('-'*70)\n",
        "\n",
        "  # Returns a list containing the prediction results and a data frame for testing.\n",
        "  return y_pred, df_test\n",
        "\n"
      ],
      "metadata": {
        "id": "65tQ7Pvnmg76"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example"
      ],
      "metadata": {
        "id": "dYF-OpMa03Ra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = ['AV', 'AC', 'PR', 'UI', 'S', 'C', 'I', 'A']\n",
        "split = 11\n",
        "\n",
        "for metric in metrics:\n",
        "  y_train, y_test, train_sentence, test_sentence, df_test = DataMake(split, metric, list_df)\n",
        "\n",
        "  X_train, vectorizer = NLP_train(train_sentence)\n",
        "  lr = MLR_train(X_train, y_train)\n",
        "\n",
        "  X_test = NLP_test(test_sentence, vectorizer)\n",
        "  MLR_test(metric, X_test, y_test, lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oB6I7HqcofQ2",
        "outputId": "9bcdf318-37c1-474e-c704-f99b5a0546e3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "metric: AV\n",
            "train: 11 test: 1\n",
            "accuracy: 0.8711995159582514\n",
            "          Predicted P  Predicted L  Predicted A  Predicted N\n",
            "Actual P           62           23          166            0\n",
            "Actual L            9         1939          731            2\n",
            "Actual A           45          616         9462            4\n",
            "Actual N            1           35           71           56\n",
            "----------------------------------------------------------------------\n",
            "metric: AC\n",
            "train: 11 test: 1\n",
            "accuracy: 0.9461503554681592\n",
            "          Predicted L  Predicted H\n",
            "Actual L          425          358\n",
            "Actual H          354        12085\n",
            "----------------------------------------------------------------------\n",
            "metric: PR\n",
            "train: 11 test: 1\n",
            "accuracy: 0.7798366359098472\n",
            "          Predicted N  Predicted L  Predicted H\n",
            "Actual N          272          308          325\n",
            "Actual L           85         1986         1527\n",
            "Actual H           43          623         8053\n",
            "----------------------------------------------------------------------\n",
            "metric: UI\n",
            "train: 11 test: 1\n",
            "accuracy: 0.8500983209801846\n",
            "          Predicted N  Predicted R\n",
            "Actual N         7929          682\n",
            "Actual R         1300         3311\n",
            "----------------------------------------------------------------------\n",
            "metric: S\n",
            "train: 11 test: 1\n",
            "accuracy: 0.9636212373317199\n",
            "          Predicted U  Predicted C\n",
            "Actual U         1706          357\n",
            "Actual C          124        11035\n",
            "----------------------------------------------------------------------\n",
            "metric: C\n",
            "train: 11 test: 1\n",
            "accuracy: 0.8243836030857662\n",
            "          Predicted N  Predicted L  Predicted H\n",
            "Actual N         7223          250          433\n",
            "Actual L          566         1755          163\n",
            "Actual H          841           69         1922\n",
            "----------------------------------------------------------------------\n",
            "metric: I\n",
            "train: 11 test: 1\n",
            "accuracy: 0.8266525487823325\n",
            "          Predicted N  Predicted L  Predicted H\n",
            "Actual N         5916          192          657\n",
            "Actual L          392         1708          132\n",
            "Actual H          867           52         3306\n",
            "----------------------------------------------------------------------\n",
            "metric: A\n",
            "train: 11 test: 1\n",
            "accuracy: 0.8605354711843897\n",
            "          Predicted N  Predicted L  Predicted H\n",
            "Actual N         7047           48          644\n",
            "Actual L          104           89           50\n",
            "Actual H          980           18         4242\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}